{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o89xzpI7Dqa6"
      },
      "source": [
        "## Assignment 2\n",
        "\n",
        "# 2. Dataset description and Overview\n",
        "The dataset used for this assignment is a sample from [EMNIST handwritten character dataset - ByClass](https://www.nist.gov/itl/products-and-services/emnist-dataset), a collection of 814,255+ 28 by 28 images with character labels. This smaller sample set can be downloaded from the Google Drive link provided in the assignment specification. The dataset consists of 120000 amount images, of which 100,000 is split into a test set, which was further divided into a validation set after pre-processing, and a testing set of 20,000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/calvin/.local/lib/python3.10/site-packages (1.26.4)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow in /home/calvin/.local/lib/python3.10/site-packages (2.17.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (1.66.2)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.25.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/calvin/.local/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: optree in /home/calvin/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: rich in /home/calvin/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /home/calvin/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/calvin/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/calvin/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/calvin/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/calvin/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/calvin/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/calvin/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/calvin/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: scikit-learn in /home/calvin/.local/lib/python3.10/site-packages (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/calvin/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/calvin/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /home/calvin/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /home/calvin/.local/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: scipy==1.12 in /home/calvin/.local/lib/python3.10/site-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /home/calvin/.local/lib/python3.10/site-packages (from scipy==1.12) (1.26.4)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in /home/calvin/.local/lib/python3.10/site-packages (2.4.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: triton==3.0.0 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (3.0.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: fsspec in /home/calvin/.local/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: networkx in /home/calvin/.local/lib/python3.10/site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/calvin/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/calvin/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchvision in /home/calvin/.local/lib/python3.10/site-packages (0.19.1)\n",
            "Requirement already satisfied: torch==2.4.1 in /home/calvin/.local/lib/python3.10/site-packages (from torchvision) (2.4.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
            "Requirement already satisfied: numpy in /home/calvin/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch==2.4.1->torchvision) (1.9)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: triton==3.0.0 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch==2.4.1->torchvision) (3.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (4.10.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (2.20.5)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.4.1->torchvision) (3.0.3)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: networkx in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (3.3)\n",
            "Requirement already satisfied: fsspec in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/calvin/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/calvin/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchvision) (12.6.77)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tqdm in /home/calvin/.local/lib/python3.10/site-packages (4.66.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchsummary in /home/calvin/.local/lib/python3.10/site-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install scipy==1.12\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install tqdm\n",
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r2-0R_-1A-Y",
        "outputId": "4d6c6b2a-2ad7-45cc-d241-5ec687915b84"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pickle\n",
        "import keras\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import class_weight\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, resnet50\n",
        "from torchvision.models.vision_transformer import vit_b_16\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import ReLU\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MyIDGGsImeR",
        "outputId": "f6423443-5bd3-45f9-bfd6-1ba4d5f9184e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing images shape: (20000, 28, 28)\n",
            "Training images shape: (100000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "train_dict = pickle.load(open('emnist_train.pkl', 'rb'))\n",
        "test_dict = pickle.load(open('emnist_test.pkl', 'rb'))\n",
        "\n",
        "# Extract the images and labels from the dictionaries\n",
        "train_images = train_dict['data']\n",
        "train_labels = train_dict['labels']\n",
        "test_images = test_dict['data']\n",
        "test_labels = test_dict['labels']\n",
        "print(\"Testing images shape:\", test_images.shape)\n",
        "print(\"Training images shape:\", train_images.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "id": "beWlCH8J5Pm6",
        "outputId": "2d5ae48c-0f26-45c1-e83a-1754cbb673a1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Number of images to display\n",
        "# num_images = 10\n",
        "\n",
        "# # Create a figure and axes for the grid\n",
        "# fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "\n",
        "# # Iterate through the sample images\n",
        "# for i in range(num_images):\n",
        "#     # Select a random image\n",
        "#     random_index = np.random.randint(0, len(train_images))\n",
        "#     image = train_images[random_index].reshape(28, 28)\n",
        "\n",
        "#     # Convert the NumPy array to a PIL image\n",
        "#     pil_image = Image.fromarray((image * 255))  # Convert to uint8 for PIL compatibility\n",
        "\n",
        "#     # Rotate the image 90 degrees clockwise\n",
        "#     rotated_image = pil_image.rotate(-90).transpose(Image.FLIP_LEFT_RIGHT) # Negative angle for clockwise rotation\n",
        "\n",
        "#     # Convert back to NumPy array for displaying with matplotlib\n",
        "#     rotated_image_np = np.array(rotated_image)\n",
        "\n",
        "#     # Display the image\n",
        "#     axes[i].imshow(rotated_image_np, cmap='gray')\n",
        "#     axes[i].axis('off')\n",
        "\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "6W-lK4vM2yLH",
        "outputId": "e837631a-fa03-46a3-ea68-607b8d9f35c5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate the frequency of each label in the training set\n",
        "train_label_counts = {}\n",
        "for label in train_labels:\n",
        "  if label not in train_label_counts:\n",
        "    train_label_counts[label] = 0\n",
        "  train_label_counts[label] += 1\n",
        "# Calculate the frequency of each label in the testing set\n",
        "test_label_counts = {}\n",
        "for label in test_labels:\n",
        "  if label not in test_label_counts:\n",
        "    test_label_counts[label] = 0\n",
        "  test_label_counts[label] += 1\n",
        "\n",
        "def display_data_distribution(train_labels, test_labels):\n",
        "\n",
        "  # Plot the histogram of training labels\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.bar(train_labels.keys(), train_labels.values())\n",
        "  plt.title('Training Label Distribution')\n",
        "  plt.xlabel('Label')\n",
        "  plt.ylabel('Frequency')\n",
        "\n",
        "  # Plot the histogram of testing labels\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.bar(test_labels.keys(), test_labels.values())\n",
        "  plt.title('Testing Label Distribution')\n",
        "  plt.xlabel('Label')\n",
        "  plt.ylabel('Frequency')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "display_data_distribution(train_label_counts, test_label_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiAOWyUnE183"
      },
      "source": [
        "# 3. Data Preparation\n",
        "\n",
        "Requred data is provided in a folder that contains a .mat file which is to be loaded in and then XXXX\n",
        "\n",
        "The folder includes:\n",
        "\n",
        "Folder details\n",
        "\n",
        "\n",
        "## 3.1 Merging Classes\n",
        "\n",
        "Due to the similarities of Uppercase and Lowercase letters, as suggested by the dataset specific images will be merged, for example lowercase 'k' is similar to uppercase \"K\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def display_images_by_label(images, labels, target_label, num_samples=5):\n",
        "    # Find the indices of images with the target label\n",
        "    indices = np.where(labels == target_label)[0]\n",
        "\n",
        "    # Display a few images with the specified label\n",
        "    if len(indices) == 0:\n",
        "        print(f\"No images found for label {target_label}\")\n",
        "        return\n",
        "\n",
        "    # Limit to the specified number of samples\n",
        "    indices = indices[:num_samples]\n",
        "\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    for i, idx in enumerate(indices):\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        rotated_image = np.rot90(images[idx].reshape(28, 28), k=1)\n",
        "\n",
        "        # Display the rotated image\n",
        "        plt.imshow(rotated_image, cmap='gray')\n",
        "        plt.title(f\"Label: {labels[idx]}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# For example, 38 is 'c' and 12 is 'C' in the original EMNIST ByClass labels.\n",
        "display_images_by_label(train_images, train_labels, target_label=46, num_samples=5)  # Display lowercase 'c'\n",
        "display_images_by_label(train_images, train_labels, target_label=20, num_samples=5)  # Display uppercase 'C'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique labels in the training set: 47\n",
            "Number of unique labels in the testing set: 47\n"
          ]
        }
      ],
      "source": [
        "merge_dictionary = {\n",
        "        38: 12,  # 'c' -> 'C'\n",
        "        44: 18,  # 'i' -> 'I'\n",
        "        45: 19,  # 'j' -> 'J'\n",
        "        46: 20,  # 'k' -> 'K'\n",
        "        47: 21,  # 'l' -> 'L'\n",
        "        48: 22,  # 'm' -> 'M'\n",
        "        50: 24,  # 'o' -> 'O'\n",
        "        51: 25,  # 'p' -> 'P'\n",
        "        54: 28,  # 's' -> 'S'\n",
        "        56: 30,  # 'u' -> 'U'\n",
        "        57: 31,  # 'v' -> 'V'\n",
        "        58: 32,  # 'w' -> 'W'\n",
        "        59: 33,  # 'x' -> 'X'\n",
        "        60: 34,  # 'y' -> 'Y'\n",
        "        61: 35   # 'z' -> 'Z'\n",
        "    }\n",
        "\n",
        "def merge_labels(labels, merge_dictionary):\n",
        "    merged_labels = np.copy(labels)\n",
        "    for old_label, new_label in merge_dictionary.items():\n",
        "        merged_labels[labels == old_label] = new_label\n",
        "    return merged_labels\n",
        "\n",
        "#Step 0\n",
        "# Merge the labels\n",
        "train_labels = merge_labels(train_labels, merge_dictionary)\n",
        "test_labels = merge_labels(test_labels, merge_dictionary)\n",
        "#Print Number of unique labels\n",
        "print(\"Number of unique labels in the training set:\", len(np.unique(train_labels)))\n",
        "print(\"Number of unique labels in the testing set:\", len(np.unique(test_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cJ49_F_pFAFL",
        "outputId": "524b68e0-ef6b-4310-8f2d-2f3226d597ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images shape (after reshaping): (90000, 28, 28, 1)\n",
            "Validation images shape: (10000, 28, 28, 1)\n",
            "Test images shape (after reshaping): (20000, 28, 28, 1)\n",
            "Class weights for balancing: {0: 0.42954096388992297, 1: 0.38251969976453787, 2: 0.4321583428168081, 3: 0.421968624288514, 4: 0.45098766298193044, 5: 0.4541967782308531, 6: 0.43235349221523517, 7: 0.414120591916366, 8: 0.44357044637972587, 9: 0.43372448856654056, 10: 2.33523611831863, 11: 3.732736095558044, 12: 1.1283993028999861, 13: 3.223726627981947, 14: 2.9459901800327333, 15: 1.5695849319846529, 16: 5.946874587022598, 17: 4.474050507059057, 18: 1.0234599770290094, 19: 2.486874827300359, 20: 3.0638297872340425, 21: 0.7206976353109811, 22: 1.2673021952490249, 23: 1.736077621959453, 24: 0.5440038684719536, 25: 1.435452486522696, 26: 5.733214422219391, 27: 2.7711919204360007, 28: 0.6502185456778529, 29: 1.5442690459849004, 30: 0.9603277918862972, 31: 2.015677491601344, 32: 1.9539730785931393, 33: 2.5772457833395377, 34: 2.1182451515722085, 35: 2.8036509766050903, 36: 1.524596828838596, 37: 2.927971891469842, 38: 1.5125541998588283, 39: 0.6048305802341366, 40: 5.275189027606823, 41: 4.180990430177459, 42: 1.7487612940833577, 43: 1.3187972569017057, 44: 5.246283882250073, 45: 1.0446773688059339, 46: 0.8278831029058696}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_labels)\n",
        "train_labels = label_encoder.transform(train_labels)\n",
        "test_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "\n",
        "# Step 1: Normalize the pixel values (0-255) to the range [0, 1]\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "# Step 2: Reshape the images for model input\n",
        "N_train = train_images.shape[0]  # Number of training images\n",
        "N_test = test_images.shape[0]    # Number of testing images\n",
        "\n",
        "# Reshape the images to (N, 28, 28, 1)\n",
        "train_images = train_images.reshape(N_train, 28, 28, 1)\n",
        "test_images = test_images.reshape(N_test, 28, 28, 1)\n",
        "\n",
        "# Step 2.5 Validation set\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_images, train_labels, train_size=0.9, random_state=42)\n",
        "\n",
        "# Step 3: Data Augmentation for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,       # Randomly rotate images by up to 10 degrees\n",
        "    width_shift_range=0.1,   # Randomly shift images horizontally by up to 10% of width\n",
        "    height_shift_range=0.1,  # Randomly shift images vertically by up to 10% of height\n",
        "    zoom_range=0.1           # Randomly zoom into images by up to 10%\n",
        ")\n",
        "\n",
        "# No augmentation for validation data, just rescaling\n",
        "valid_datagen = ImageDataGenerator()\n",
        "\n",
        "# Fit the data generator on the training images\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "\n",
        "# Step 4.5: Class Rebalancing\n",
        "# Compute class weights to account for class imbalance\n",
        "classes = np.unique(y_train)\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Summary of preprocessing steps\n",
        "print(\"Train images shape (after reshaping):\", X_train.shape)\n",
        "print(\"Validation images shape:\", X_valid.shape)\n",
        "print(\"Test images shape (after reshaping):\", test_images.shape)\n",
        "print(\"Class weights for balancing:\", class_weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "        # Define the transformations: resize and convert to 3 channels\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),                    # Convert tensor to PIL Image\n",
        "            transforms.Resize(224),                     # Resize image to 224x224 pixels\n",
        "            transforms.Grayscale(num_output_channels=3),# Convert to 3 channels by duplicating the grayscale channel\n",
        "            transforms.ToTensor()                       # Convert back to tensor\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Apply the transformations\n",
        "        image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# # Create datasets with transforms\n",
        "train_dataset = CustomDataset(train_images, train_labels)\n",
        "test_dataset = CustomDataset(test_images, test_labels)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1728708907.146813  588251 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1728708907.147420  588251 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-12 15:55:07.154103: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
              "\n",
              " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">13,872</span> \n",
              "\n",
              " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">27,712</span> \n",
              "\n",
              " batch_normalization_2            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
              "\n",
              " batch_normalization_3            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> \n",
              "\n",
              " batch_normalization_4            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
              "\n",
              " batch_normalization_5            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,063</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m320\u001b[0m \n",
              "\n",
              " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m128\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " re_lu (\u001b[38;5;33mReLU\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m48\u001b[0m)             \u001b[38;5;34m13,872\u001b[0m \n",
              "\n",
              " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m48\u001b[0m)                \u001b[38;5;34m192\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m48\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               \u001b[38;5;34m27,712\u001b[0m \n",
              "\n",
              " batch_normalization_2            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m256\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m73,856\u001b[0m \n",
              "\n",
              " batch_normalization_3            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m147,584\u001b[0m \n",
              "\n",
              " batch_normalization_4            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m16,512\u001b[0m \n",
              "\n",
              " batch_normalization_5            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m)                      \u001b[38;5;34m6,063\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288,031</span> (1.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m288,031\u001b[0m (1.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">286,975</span> (1.09 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m286,975\u001b[0m (1.09 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> (4.12 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,056\u001b[0m (4.12 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define and instantiate CNN\n",
        "\n",
        "keras.backend.clear_session()\n",
        "\n",
        "cnn = keras.Sequential([\n",
        "    keras.Input(shape=(28, 28, 1)),  # Input shape for EMNIST data\n",
        "\n",
        "    # First Conv Block\n",
        "    keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "\n",
        "    # Second Conv Block\n",
        "    keras.layers.Conv2D(48, kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "\n",
        "    # Third Conv Block\n",
        "    keras.layers.Conv2D(64, kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "\n",
        "    # Fourth Conv Block\n",
        "    keras.layers.Conv2D(128, kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "\n",
        "    # Flatten Layer\n",
        "    keras.layers.Flatten(),\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    keras.layers.Dense(128),  # No activation here, add as a separate layer\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(128),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(len(classes), activation=\"softmax\"),  # Output layer for classification\n",
        "])\n",
        "\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/calvin/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/home/calvin/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=47, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the Vision Transformer and Resnet 18\n",
        "num_classes = len(np.unique(train_labels))\n",
        "resnet = resnet18(num_classes, pretrained=False)\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
        "print(resnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/calvin/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m704/704\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 113ms/step - accuracy: 0.4030 - loss: 2.3820 - val_accuracy: 0.8189 - val_loss: 0.5709\n",
            "Epoch 2/30\n",
            "\u001b[1m413/704\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - accuracy: 0.7396 - loss: 0.7813"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Compile model with adjusted learning rate for Adam optimizer\n",
        "learning_rate = 0.0005  # Decreasing the learning rate for better convergence\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "cnn.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set batch size and number of epochs\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "\n",
        "# Fit the model\n",
        "history = cnn.fit(train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                    epochs=epochs, validation_data=valid_datagen.flow(X_valid, y_valid, batch_size=batch_size),\n",
        "                    class_weight=class_weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/calvin/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/calvin/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VisionTransformer(\n",
            "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "  (encoder): Encoder(\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "    (layers): Sequential(\n",
            "      (encoder_layer_0): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_1): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_2): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_3): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_4): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_5): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_6): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_7): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_8): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_9): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_10): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_11): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (heads): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=47, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "vit = vit_b_16(pretrained=False)\n",
        "vit.heads = nn.Sequential(\n",
        "    nn.Linear(in_features=768, out_features=num_classes)\n",
        ")\n",
        "\n",
        "print(vit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "\n",
        "# Function to generate all combinations of hyperparameters\n",
        "def generate_hyperparam_combinations(param_grid):\n",
        "    keys, values = zip(*param_grid.items())\n",
        "    return [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "def train_model(\n",
        "    model, \n",
        "    train_loader, \n",
        "    test_loader, \n",
        "    train_labels, \n",
        "    class_weights_dict, \n",
        "    num_epochs=10, \n",
        "    learning_rate=0.0001, \n",
        "    optimizer_name='Adam', \n",
        "    momentum=0.9, \n",
        "    weight_decay=0.0, \n",
        "    scheduler_name=None, \n",
        "    step_size=5, \n",
        "    gamma=0.1, \n",
        "    patience=2\n",
        "):\n",
        "    # Set device (GPU if available)\n",
        "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Prepare class weights\n",
        "    classes = np.unique(train_labels)\n",
        "    class_weights_list = [class_weights_dict[cls] for cls in classes]\n",
        "    class_weights_tensor = torch.tensor(class_weights_list, dtype=torch.float).to(device)\n",
        "\n",
        "    # Define loss function with class weights\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "    # Define optimizer\n",
        "    if optimizer_name == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
        "\n",
        "    # Define learning rate scheduler if provided\n",
        "    if scheduler_name == 'StepLR':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "    elif scheduler_name == 'ReduceLROnPlateau':\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=patience, factor=gamma)\n",
        "    else:\n",
        "        scheduler = None  # No scheduler by default\n",
        "\n",
        "    # Training Loop with Progress Bar\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with tqdm(total=len(train_loader), desc=f\"Epoch [{epoch+1}/{num_epochs}]\", unit=\"batch\") as pbar:\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Update metrics\n",
        "                running_loss += loss.item() * images.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                pbar.update(1)\n",
        "                pbar.set_postfix(loss=running_loss / total, accuracy=100.0 * correct / total)\n",
        "\n",
        "        # Validation Loop (Calculate Test Accuracy, Precision, Recall after Each Epoch)\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = outputs.max(1)\n",
        "                \n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "        recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "        conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}] Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}')\n",
        "\n",
        "        # Step the scheduler if available\n",
        "        if scheduler_name == 'ReduceLROnPlateau':\n",
        "            scheduler.step(running_loss / total)  # Step with validation loss\n",
        "        elif scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    # Calculate final metrics after all training epochs\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            \n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    final_test_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    final_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    final_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    final_conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(f'Final Test Accuracy: {final_test_accuracy:.2f}, Precision: {final_precision:.2f}, Recall: {final_recall:.2f}')\n",
        "\n",
        "    return {\n",
        "        'final_test_accuracy': final_test_accuracy,\n",
        "        'precision': final_precision,\n",
        "        'recall': final_recall,\n",
        "        'confusion_matrix': final_conf_matrix\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]: 100%|| 3125/3125 [06:57<00:00,  7.48batch/s, accuracy=88.3, loss=0.284]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] Accuracy: 0.87, Precision: 0.89, Recall: 0.87\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [2/10]: 100%|| 3125/3125 [07:43<00:00,  6.74batch/s, accuracy=89.4, loss=0.24] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10] Accuracy: 0.88, Precision: 0.90, Recall: 0.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [3/10]: 100%|| 3125/3125 [07:47<00:00,  6.69batch/s, accuracy=90.1, loss=0.208]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10] Accuracy: 0.89, Precision: 0.90, Recall: 0.89\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [4/10]: 100%|| 3125/3125 [07:43<00:00,  6.74batch/s, accuracy=90.9, loss=0.182]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10] Accuracy: 0.90, Precision: 0.90, Recall: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [5/10]: 100%|| 3125/3125 [07:44<00:00,  6.72batch/s, accuracy=91.5, loss=0.159]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10] Accuracy: 0.90, Precision: 0.91, Recall: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [6/10]: 100%|| 3125/3125 [07:42<00:00,  6.76batch/s, accuracy=92.2, loss=0.135]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10] Accuracy: 0.89, Precision: 0.90, Recall: 0.89\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [7/10]: 100%|| 3125/3125 [07:11<00:00,  7.24batch/s, accuracy=92.9, loss=0.12] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10] Accuracy: 0.90, Precision: 0.90, Recall: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [8/10]: 100%|| 3125/3125 [06:57<00:00,  7.48batch/s, accuracy=93.4, loss=0.107] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10] Accuracy: 0.90, Precision: 0.90, Recall: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [9/10]: 100%|| 3125/3125 [06:18<00:00,  8.26batch/s, accuracy=93.9, loss=0.0942]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/10] Accuracy: 0.90, Precision: 0.90, Recall: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [10/10]: 100%|| 3125/3125 [07:15<00:00,  7.17batch/s, accuracy=94.5, loss=0.0838]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/10] Accuracy: 0.90, Precision: 0.90, Recall: 0.90\n",
            "Final Test Accuracy: 0.90, Precision: 0.90, Recall: 0.90\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'final_test_accuracy': 0.89745,\n",
              " 'precision': 0.8993416157920888,\n",
              " 'recall': 0.89745,\n",
              " 'confusion_matrix': array([[623,   0,   0, ...,   0,   0,   0],\n",
              "        [  0, 713,   1, ...,   0,   0,   1],\n",
              "        [  0,   0, 974, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0, ...,  28,   0,   0],\n",
              "        [  0,   0,   0, ...,   1, 390,   0],\n",
              "        [  0,   0,   0, ...,   0,   3, 476]])}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train resnet\n",
        "\n",
        "train_model(model=resnet, train_loader=train_loader, test_loader=test_loader, train_labels=train_labels, class_weights_dict=class_weights_dict, num_epochs=10, learning_rate=5e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
